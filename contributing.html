<!DOCTYPE html>
<html>

<head>
  <meta charset="UTF-8">
  <title>Contribute to REval Leaderboard</title>
  <link rel="icon" href="https://images.emojiterra.com/google/noto-emoji/unicode-15/color/1024px/1f9d1-1f4bb.png">
</head>

<h1>Contributing</h1>

We greatly welcome contributions to benchmark results.

To add evaluation results of new models, simply

<ol type="1">
  <li> <a href="https://github.com/r-eval/r-eval.github.io/fork" target="_blank">Fork</a> the leaderboard repository. </li>
  <li> Add model information in <a href="https://github.com/r-eval/r-eval.github.io/blob/main/model_url_map.json" target="_blank"><code>model_url_map.json</code></a> and evaluation results in <a href="https://github.com/r-eval/r-eval.github.io/blob/main/model_url_map.json" target="_blank"><code>results.json</code></a>. Note that the model names in the two files should match. </li>
  <li> Create a pull request. Please describe your evaluation environment (OS & software versions, hardware specifications, etc.). </li>
</ol>

<hr/>
  
<a href="javascript:history.back()">Back</a>

</html>
